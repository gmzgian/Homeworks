Spark SQl:


import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .master("local[*]") \
    .appName('test') \
    .getOrCreate()
    
   -----------------------------
   
   from pyspark.sql import functions as F
   
   -------------------------------
   
spark.sql("""
SELECT
    count(1)
FROM
    fhvhv
WHERE pickup_datetime >= '2021-06-15 00:00:00' AND pickup_datetime < '2021-06-16 00:00:00'
""").show()
+--------+
|count(1)|
+--------+
|  452470|
+--------+

-------------------

spark.sql("""
SELECT
pickup_datetime,
dropoff_datetime,
    datediff(dropoff_datetime, pickup_datetime)*24 AS TripDuration
FROM
    fhvhv
order by TripDuration DESC
LIMIT 1
""").show()

+-------------------+-------------------+------------+
|    pickup_datetime|   dropoff_datetime|TripDuration|
+-------------------+-------------------+------------+
|2021-06-25 13:55:41|2021-06-28 08:48:25|          72|
+-------------------+-------------------+------------+

-------------------

df_result = df_fhvhv.join(df_zones, df_fhvhv.PULocationID == df_zones.LocationID)

---------------------

spark.sql("""
SELECT
    Zone,
    count(1) as count
FROM
    fhvhv_zones
group by Zone
order by count DESC
limit 1
""").show()

+-------------------+------+
|               Zone| count|
+-------------------+------+
|Crown Heights North|231279|
+-------------------+------+
